{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8847660,"sourceType":"datasetVersion","datasetId":5325404}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/wdrink/M2TR-Multi-modal-Multi-scale-Transformers-for-Deepfake-Detection.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T07:11:24.493385Z","iopub.execute_input":"2024-12-21T07:11:24.493655Z","iopub.status.idle":"2024-12-21T07:11:25.336280Z","shell.execute_reply.started":"2024-12-21T07:11:24.493634Z","shell.execute_reply":"2024-12-21T07:11:25.335383Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'M2TR-Multi-modal-Multi-scale-Transformers-for-Deepfake-Detection'...\nremote: Enumerating objects: 119, done.\u001b[K\nremote: Counting objects: 100% (119/119), done.\u001b[K\nremote: Compressing objects: 100% (84/84), done.\u001b[K\nremote: Total 119 (delta 52), reused 79 (delta 31), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (119/119), 1.80 MiB | 27.85 MiB/s, done.\nResolving deltas: 100% (52/52), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%cd /kaggle/working/M2TR-Multi-modal-Multi-scale-Transformers-for-Deepfake-Detection","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T07:11:27.203579Z","iopub.execute_input":"2024-12-21T07:11:27.203903Z","iopub.status.idle":"2024-12-21T07:11:27.209885Z","shell.execute_reply.started":"2024-12-21T07:11:27.203876Z","shell.execute_reply":"2024-12-21T07:11:27.209226Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/M2TR-Multi-modal-Multi-scale-Transformers-for-Deepfake-Detection\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install -r requirements.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T07:11:44.539147Z","iopub.execute_input":"2024-12-21T07:11:44.539511Z","iopub.status.idle":"2024-12-21T07:11:54.784169Z","shell.execute_reply.started":"2024-12-21T07:11:44.539486Z","shell.execute_reply":"2024-12-21T07:11:54.783291Z"}},"outputs":[{"name":"stdout","text":"Collecting absl-py==1.0.0 (from -r requirements.txt (line 1))\n  Downloading absl_py-1.0.0-py3-none-any.whl.metadata (2.3 kB)\nCollecting albumentations==1.1.0 (from -r requirements.txt (line 2))\n  Downloading albumentations-1.1.0-py3-none-any.whl.metadata (31 kB)\nCollecting cachetools==5.0.0 (from -r requirements.txt (line 3))\n  Downloading cachetools-5.0.0-py3-none-any.whl.metadata (4.5 kB)\nCollecting certifi==2021.10.8 (from -r requirements.txt (line 4))\n  Downloading certifi-2021.10.8-py2.py3-none-any.whl.metadata (3.0 kB)\nCollecting charset-normalizer==2.0.12 (from -r requirements.txt (line 5))\n  Downloading charset_normalizer-2.0.12-py3-none-any.whl.metadata (11 kB)\nCollecting fvcore==0.1.5.post20220414 (from -r requirements.txt (line 6))\n  Downloading fvcore-0.1.5.post20220414.tar.gz (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting google-auth==2.6.5 (from -r requirements.txt (line 7))\n  Downloading google_auth-2.6.5-py2.py3-none-any.whl.metadata (3.6 kB)\nCollecting google-auth-oauthlib==0.4.6 (from -r requirements.txt (line 8))\n  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\nCollecting grpcio==1.44.0 (from -r requirements.txt (line 9))\n  Downloading grpcio-1.44.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\nCollecting idna==3.3 (from -r requirements.txt (line 10))\n  Downloading idna-3.3-py3-none-any.whl.metadata (9.8 kB)\nCollecting imageio==2.16.2 (from -r requirements.txt (line 11))\n  Downloading imageio-2.16.2-py3-none-any.whl.metadata (4.2 kB)\nCollecting importlib-metadata==4.11.3 (from -r requirements.txt (line 12))\n  Downloading importlib_metadata-4.11.3-py3-none-any.whl.metadata (4.0 kB)\nCollecting iopath==0.1.9 (from -r requirements.txt (line 13))\n  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\nCollecting joblib==1.1.0 (from -r requirements.txt (line 14))\n  Downloading joblib-1.1.0-py2.py3-none-any.whl.metadata (5.2 kB)\nCollecting kornia==0.6.4 (from -r requirements.txt (line 15))\n  Downloading kornia-0.6.4-py2.py3-none-any.whl.metadata (12 kB)\nCollecting Markdown==3.3.6 (from -r requirements.txt (line 16))\n  Downloading Markdown-3.3.6-py3-none-any.whl.metadata (4.6 kB)\nCollecting networkx==2.8 (from -r requirements.txt (line 17))\n  Downloading networkx-2.8-py3-none-any.whl.metadata (5.0 kB)\nCollecting numpy==1.22.3 (from -r requirements.txt (line 18))\n  Downloading numpy-1.22.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\nCollecting oauthlib==3.2.0 (from -r requirements.txt (line 19))\n  Downloading oauthlib-3.2.0-py3-none-any.whl.metadata (7.4 kB)\nCollecting opencv-python-headless==4.5.5.64 (from -r requirements.txt (line 20))\n  Downloading opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\nCollecting packaging==21.3 (from -r requirements.txt (line 21))\n  Downloading packaging-21.3-py3-none-any.whl.metadata (15 kB)\nCollecting Pillow==9.1.0 (from -r requirements.txt (line 22))\n  Downloading Pillow-9.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\nCollecting portalocker==2.4.0 (from -r requirements.txt (line 23))\n  Downloading portalocker-2.4.0-py2.py3-none-any.whl.metadata (6.8 kB)\nCollecting protobuf==3.20.0 (from -r requirements.txt (line 24))\n  Downloading protobuf-3.20.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (698 bytes)\nCollecting pyasn1==0.4.8 (from -r requirements.txt (line 25))\n  Downloading pyasn1-0.4.8-py2.py3-none-any.whl.metadata (1.5 kB)\nCollecting pyasn1-modules==0.2.8 (from -r requirements.txt (line 26))\n  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl.metadata (1.9 kB)\nCollecting pyparsing==3.0.8 (from -r requirements.txt (line 27))\n  Downloading pyparsing-3.0.8-py3-none-any.whl.metadata (4.2 kB)\nCollecting PyWavelets==1.3.0 (from -r requirements.txt (line 28))\n  Downloading PyWavelets-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\nCollecting PyYAML==6.0 (from -r requirements.txt (line 29))\n  Downloading PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (2.0 kB)\nCollecting qudida==0.0.4 (from -r requirements.txt (line 30))\n  Downloading qudida-0.0.4-py3-none-any.whl.metadata (1.5 kB)\nCollecting requests==2.27.1 (from -r requirements.txt (line 31))\n  Downloading requests-2.27.1-py2.py3-none-any.whl.metadata (5.0 kB)\nRequirement already satisfied: requests-oauthlib==1.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 32)) (1.3.1)\nCollecting rsa==4.8 (from -r requirements.txt (line 33))\n  Downloading rsa-4.8-py3-none-any.whl.metadata (3.1 kB)\nCollecting scikit-image==0.19.2 (from -r requirements.txt (line 34))\n  Downloading scikit_image-0.19.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\nCollecting scikit-learn==1.0.2 (from -r requirements.txt (line 35))\n  Downloading scikit_learn-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\nCollecting scipy==1.8.0 (from -r requirements.txt (line 36))\n  Downloading scipy-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\nCollecting simplejson==3.17.6 (from -r requirements.txt (line 37))\n  Downloading simplejson-3.17.6-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (3.0 kB)\nRequirement already satisfied: six==1.16.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 38)) (1.16.0)\nCollecting tabulate==0.8.9 (from -r requirements.txt (line 39))\n  Downloading tabulate-0.8.9-py3-none-any.whl.metadata (23 kB)\nCollecting tensorboard==2.8.0 (from -r requirements.txt (line 40))\n  Downloading tensorboard-2.8.0-py3-none-any.whl.metadata (1.9 kB)\nCollecting tensorboard-data-server==0.6.1 (from -r requirements.txt (line 41))\n  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\nCollecting tensorboard-plugin-wit==1.8.1 (from -r requirements.txt (line 42))\n  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\nCollecting termcolor==1.1.0 (from -r requirements.txt (line 43))\n  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting threadpoolctl==3.1.0 (from -r requirements.txt (line 44))\n  Downloading threadpoolctl-3.1.0-py3-none-any.whl.metadata (9.2 kB)\nCollecting tifffile==2022.4.8 (from -r requirements.txt (line 45))\n  Downloading tifffile-2022.4.8-py3-none-any.whl.metadata (26 kB)\nCollecting timm==0.5.4 (from -r requirements.txt (line 46))\n  Downloading timm-0.5.4-py3-none-any.whl.metadata (36 kB)\n\u001b[31mERROR: Ignored the following versions that require a different python version: 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.11.0+cu113 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.11.0+cu113\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install fvcore","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T07:11:54.785334Z","iopub.execute_input":"2024-12-21T07:11:54.785576Z","iopub.status.idle":"2024-12-21T07:12:02.106677Z","shell.execute_reply.started":"2024-12-21T07:11:54.785554Z","shell.execute_reply":"2024-12-21T07:12:02.105825Z"}},"outputs":[{"name":"stdout","text":"Collecting fvcore\n  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore) (1.26.4)\nCollecting yacs>=0.1.6 (from fvcore)\n  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore) (6.0.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fvcore) (4.66.5)\nRequirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from fvcore) (2.4.0)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from fvcore) (10.4.0)\nRequirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fvcore) (0.9.0)\nCollecting iopath>=0.1.7 (from fvcore)\n  Downloading iopath-0.1.10.tar.gz (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from iopath>=0.1.7->fvcore) (4.12.2)\nCollecting portalocker (from iopath>=0.1.7->fvcore)\n  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\nDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\nDownloading portalocker-3.0.0-py3-none-any.whl (19 kB)\nBuilding wheels for collected packages: fvcore, iopath\n  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61395 sha256=dfec3cedd194b473ac258897e6aa8d013e69dfa2208afbe63c3af8df50fd7fe9\n  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31529 sha256=5740d421bd007e252075b4a7da83853d0908d9872bb53e83f834361d3e733a8d\n  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\nSuccessfully built fvcore iopath\nInstalling collected packages: yacs, portalocker, iopath, fvcore\nSuccessfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-3.0.0 yacs-0.1.8\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!pip install simplejson","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T07:12:02.108166Z","iopub.execute_input":"2024-12-21T07:12:02.108444Z","iopub.status.idle":"2024-12-21T07:12:05.917216Z","shell.execute_reply.started":"2024-12-21T07:12:02.108423Z","shell.execute_reply":"2024-12-21T07:12:05.916267Z"}},"outputs":[{"name":"stdout","text":"Collecting simplejson\n  Downloading simplejson-3.19.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\nDownloading simplejson-3.19.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: simplejson\nSuccessfully installed simplejson-3.19.3\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!pip install -U albumentations","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T07:12:05.918912Z","iopub.execute_input":"2024-12-21T07:12:05.919243Z","iopub.status.idle":"2024-12-21T07:12:11.763353Z","shell.execute_reply.started":"2024-12-21T07:12:05.919212Z","shell.execute_reply":"2024-12-21T07:12:11.762534Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.4.15)\nCollecting albumentations\n  Downloading albumentations-1.4.23-py3-none-any.whl.metadata (36 kB)\nRequirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.26.4)\nRequirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.13.1)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.2)\nRequirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.10/dist-packages (from albumentations) (2.9.2)\nCollecting albucore==0.0.21 (from albumentations)\n  Downloading albucore-0.0.21-py3-none-any.whl.metadata (5.3 kB)\nRequirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.2.0)\nRequirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.10.0.84)\nCollecting stringzilla>=3.10.4 (from albucore==0.0.21->albumentations)\n  Downloading stringzilla-3.11.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (80 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.1/80.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting simsimd>=5.9.2 (from albucore==0.0.21->albumentations)\n  Downloading simsimd-6.2.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (66 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.0/66.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9.2->albumentations) (2.23.4)\nRequirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9.2->albumentations) (4.12.2)\nDownloading albumentations-1.4.23-py3-none-any.whl (269 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.9/269.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading albucore-0.0.21-py3-none-any.whl (12 kB)\nDownloading simsimd-6.2.1-cp310-cp310-manylinux_2_28_x86_64.whl (632 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m632.7/632.7 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading stringzilla-3.11.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (303 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.5/303.5 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: stringzilla, simsimd, albucore, albumentations\n  Attempting uninstall: albucore\n    Found existing installation: albucore 0.0.16\n    Uninstalling albucore-0.0.16:\n      Successfully uninstalled albucore-0.0.16\n  Attempting uninstall: albumentations\n    Found existing installation: albumentations 1.4.15\n    Uninstalling albumentations-1.4.15:\n      Successfully uninstalled albumentations-1.4.15\nSuccessfully installed albucore-0.0.21 albumentations-1.4.23 simsimd-6.2.1 stringzilla-3.11.2\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport csv\nimport os\nimport imageio.v2 as imageio\n\nimport fvcore\nimport simplejson\n\nimport torchvision\nimport torchvision.transforms as transforms\n\nfrom torch.utils.data import Dataset, DataLoader, random_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T07:12:11.764376Z","iopub.execute_input":"2024-12-21T07:12:11.764597Z","iopub.status.idle":"2024-12-21T07:12:16.227083Z","shell.execute_reply.started":"2024-12-21T07:12:11.764578Z","shell.execute_reply":"2024-12-21T07:12:16.226355Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T07:12:16.227988Z","iopub.execute_input":"2024-12-21T07:12:16.228343Z","iopub.status.idle":"2024-12-21T07:12:16.231767Z","shell.execute_reply.started":"2024-12-21T07:12:16.228321Z","shell.execute_reply":"2024-12-21T07:12:16.231049Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"#!python run.py --cfg m2tr.yaml","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import math\n\nimport torch\nimport torch.fft\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom M2TR.utils.registries import MODEL_REGISTRY\n\nfrom M2TR.models.base import BaseNetwork\nfrom M2TR.models.xception import Xception\nfrom M2TR.models.efficientnet import EfficientNet\nfrom M2TR.models.modules.head import Classifier2D, Localizer\nfrom M2TR.models.modules.transformer_block import FeedForward2D\n\n\n\nclass GlobalFilter(nn.Module):\n    def __init__(self, dim=32, h=80, w=41, fp32fft=True):\n        super().__init__()\n        self.complex_weight = nn.Parameter(\n            torch.randn(h, w, dim, 2, dtype=torch.float32) * 0.02\n        )\n        self.w = w\n        self.h = h\n        self.fp32fft = fp32fft\n\n    def forward(self, x):\n        b, _, a, b = x.size()\n        x = x.permute(0, 2, 3, 1).contiguous()\n\n        if self.fp32fft:\n            dtype = x.dtype\n            x = x.to(torch.float32)\n\n        x = torch.fft.rfft2(x, dim=(1, 2), norm=\"ortho\")\n        weight = torch.view_as_complex(self.complex_weight)\n        x = x * weight\n        x = torch.fft.irfft2(x, s=(a, b), dim=(1, 2), norm=\"ortho\")\n\n        if self.fp32fft:\n            x = x.to(dtype)\n\n        x = x.permute(0, 3, 1, 2).contiguous()\n\n        return x\n\n\nclass FreqBlock(nn.Module):\n    def __init__(self, dim, h=80, w=41, fp32fft=True):\n        super().__init__()\n        self.filter = GlobalFilter(dim, h=h, w=w, fp32fft=fp32fft)\n        self.feed_forward = FeedForward2D(in_channel=dim, out_channel=dim)\n\n    def forward(self, x):\n        x = x + self.feed_forward(self.filter(x))\n        return x\n\n\ndef attention(query, key, value):\n    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(\n        query.size(-1)\n    )\n    p_attn = F.softmax(scores, dim=-1)\n    p_val = torch.matmul(p_attn, value)\n    return p_val, p_attn\n\n\nclass MultiHeadedAttention(nn.Module):\n    \"\"\"\n    Take in model size and number of heads.\n    \"\"\"\n\n    def __init__(self, patchsize, d_model):\n        super().__init__()\n        self.patchsize = patchsize\n        self.query_embedding = nn.Conv2d(\n            d_model, d_model, kernel_size=1, padding=0\n        )\n        self.value_embedding = nn.Conv2d(\n            d_model, d_model, kernel_size=1, padding=0\n        )\n        self.key_embedding = nn.Conv2d(\n            d_model, d_model, kernel_size=1, padding=0\n        )\n        self.output_linear = nn.Sequential(\n            nn.Conv2d(d_model, d_model, kernel_size=3, padding=1),\n            nn.BatchNorm2d(d_model),\n            nn.LeakyReLU(0.2, inplace=True),\n        )\n\n    def forward(self, x):\n        b, c, h, w = x.size()\n        d_k = c // len(self.patchsize)\n        output = []\n        _query = self.query_embedding(x)\n        _key = self.key_embedding(x)\n        _value = self.value_embedding(x)\n        attentions = []\n        for (width, height), query, key, value in zip(\n            self.patchsize,\n            torch.chunk(_query, len(self.patchsize), dim=1),\n            torch.chunk(_key, len(self.patchsize), dim=1),\n            torch.chunk(_value, len(self.patchsize), dim=1),\n        ):\n            out_w, out_h = w // width, h // height\n\n            # 1) embedding and reshape\n            query = query.view(b, d_k, out_h, height, out_w, width)\n            query = (\n                query.permute(0, 2, 4, 1, 3, 5)\n                .contiguous()\n                .view(b, out_h * out_w, d_k * height * width)\n            )\n            key = key.view(b, d_k, out_h, height, out_w, width)\n            key = (\n                key.permute(0, 2, 4, 1, 3, 5)\n                .contiguous()\n                .view(b, out_h * out_w, d_k * height * width)\n            )\n            value = value.view(b, d_k, out_h, height, out_w, width)\n            value = (\n                value.permute(0, 2, 4, 1, 3, 5)\n                .contiguous()\n                .view(b, out_h * out_w, d_k * height * width)\n            )\n\n            y, _ = attention(query, key, value)\n\n            # 3) \"Concat\" using a view and apply a final linear.\n            y = y.view(b, out_h, out_w, d_k, height, width)\n            y = y.permute(0, 3, 1, 4, 2, 5).contiguous().view(b, d_k, h, w)\n            attentions.append(y)\n            output.append(y)\n\n        output = torch.cat(output, 1)\n        self_attention = self.output_linear(output)\n\n        return self_attention\n\n\nclass TransformerBlock(nn.Module):\n    \"\"\"\n    Transformer = MultiHead_Attention + Feed_Forward with sublayer connection\n    \"\"\"\n\n    def __init__(self, patchsize, in_channel=256):\n        super().__init__()\n        self.attention = MultiHeadedAttention(patchsize, d_model=in_channel)\n        self.feed_forward = FeedForward2D(\n            in_channel=in_channel, out_channel=in_channel\n        )\n\n    def forward(self, rgb):\n        self_attention = self.attention(rgb)\n        output = rgb + self_attention\n        output = output + self.feed_forward(output)\n        return output\n\n\nclass CMA_Block(nn.Module):\n    def __init__(self, in_channel, hidden_channel, out_channel):\n        super(CMA_Block, self).__init__()\n\n        self.conv1 = nn.Conv2d(\n            in_channel, hidden_channel, kernel_size=1, stride=1, padding=0\n        )\n        self.conv2 = nn.Conv2d(\n            in_channel, hidden_channel, kernel_size=1, stride=1, padding=0\n        )\n        self.conv3 = nn.Conv2d(\n            in_channel, hidden_channel, kernel_size=1, stride=1, padding=0\n        )\n\n        self.scale = hidden_channel ** -0.5\n\n        self.conv4 = nn.Sequential(\n            nn.Conv2d(\n                hidden_channel, out_channel, kernel_size=1, stride=1, padding=0\n            ),\n            nn.BatchNorm2d(out_channel),\n            nn.LeakyReLU(0.2, inplace=True),\n        )\n\n    def forward(self, rgb, freq):\n        _, _, h, w = rgb.size()\n\n        q = self.conv1(rgb)\n        k = self.conv2(freq)\n        v = self.conv3(freq)\n\n        q = q.view(q.size(0), q.size(1), q.size(2) * q.size(3)).transpose(\n            -2, -1\n        )\n        k = k.view(k.size(0), k.size(1), k.size(2) * k.size(3))\n\n        attn = torch.matmul(q, k) * self.scale\n        m = attn.softmax(dim=-1)\n\n        v = v.view(v.size(0), v.size(1), v.size(2) * v.size(3)).transpose(\n            -2, -1\n        )\n        z = torch.matmul(m, v)\n        z = z.view(z.size(0), h, w, -1)\n        z = z.permute(0, 3, 1, 2).contiguous()\n\n        output = rgb + self.conv4(z)\n\n        return output\n\n\nclass PatchTrans(BaseNetwork):\n    def __init__(self, in_channel, in_size):\n        super(PatchTrans, self).__init__()\n        self.in_size = in_size\n\n        patchsize = [\n            (in_size, in_size),\n            (in_size // 2, in_size // 2),\n            (in_size // 4, in_size // 4),\n            (in_size // 8, in_size // 8),\n        ]\n\n        self.t = TransformerBlock(patchsize, in_channel=in_channel)\n\n    def forward(self, enc_feat):\n        output = self.t(enc_feat)\n        return output\n\n\n#@MODEL_REGISTRY.register()\nclass M2TR(BaseNetwork):\n    def __init__(self, model_cfg):\n        super(M2TR, self).__init__()\n        img_size = model_cfg[\"IMG_SIZE\"]\n        backbone = model_cfg[\"BACKBONE\"]\n        texture_layer = model_cfg[\"TEXTURE_LAYER\"]\n        feature_layer = model_cfg[\"FEATURE_LAYER\"]\n        depth = model_cfg[\"DEPTH\"]\n        num_classes = model_cfg[\"NUM_CLASSES\"]\n        drop_ratio = model_cfg[\"DROP_RATIO\"]\n        has_decoder = model_cfg[\"HAS_DECODER\"]\n\n        freq_h = img_size // 4\n        freq_w = freq_h // 2 + 1\n\n        if \"xception\" in backbone:\n            self.model = Xception(num_classes)\n        elif backbone.split(\"-\")[0] == \"efficientnet\":\n            self.model = EfficientNet({'NAME': backbone, 'PRETRAINED': True})\n\n        self.texture_layer = texture_layer\n        self.feature_layer = feature_layer\n\n        with torch.no_grad():\n            input = {\"img\": torch.zeros(1, 3, img_size, img_size)}\n            layers = self.model(input)\n        texture_dim = layers[self.texture_layer].shape[1]\n        feature_dim = layers[self.feature_layer].shape[1]\n\n        self.layers = nn.ModuleList([])\n        for _ in range(depth):\n            self.layers.append(\n                nn.ModuleList(\n                    [\n                        PatchTrans(in_channel=texture_dim, in_size=freq_h),\n                        FreqBlock(dim=texture_dim, h=freq_h, w=freq_w),\n                        CMA_Block(\n                            in_channel=texture_dim,\n                            hidden_channel=texture_dim,\n                            out_channel=texture_dim,\n                        ),\n                    ]\n                )\n            )\n\n        self.classifier = Classifier2D(\n            feature_dim, num_classes, drop_ratio, \"softmax\"\n        )\n\n        self.has_decoder = has_decoder\n        if self.has_decoder:\n            self.decoder = Localizer(texture_dim, 1)\n\n    def forward(self, x):\n        rgb = x #[\"img\"]\n        B = rgb.size(0)\n\n        layers = {}\n        rgb = self.model.extract_textures(rgb, layers)\n\n        for attn, filter, cma in self.layers:\n            rgb = attn(rgb)\n            freq = filter(rgb)\n            rgb = cma(rgb, freq)\n\n        features = self.model.extract_features(rgb, layers)\n        features = F.adaptive_avg_pool2d(features, (1, 1))\n        features = features.view(B, features.size(1))\n\n        logits = self.classifier(features)\n\n        if self.has_decoder:\n            mask = self.decoder(rgb)\n            mask = mask.squeeze(-1)\n\n        else:\n            mask = None\n\n        output = {\"logits\": logits, \"mask\": mask, \"features:\": features}\n        return output\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T07:12:16.232634Z","iopub.execute_input":"2024-12-21T07:12:16.232923Z","iopub.status.idle":"2024-12-21T07:12:19.790107Z","shell.execute_reply.started":"2024-12-21T07:12:16.232893Z","shell.execute_reply":"2024-12-21T07:12:19.789252Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from torchsummary import summary\n\n\nmodel_cfg = {\"IMG_SIZE\":256,\n             \"BACKBONE\": 'efficientnet-b4',\n             \"TEXTURE_LAYER\":'b2',\n             \"FEATURE_LAYER\": 'final',\n             \"DEPTH\":4,\n             \"NUM_CLASSES\":2,\n             \"DROP_RATIO\":0.5,\n             \"HAS_DECODER\":False}\n\n\nmodel = M2TR(model_cfg)\nmodel.cuda()\n# summary(model, input_size=(3, 256, 256), batch_size=12, device=\"cuda\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T07:12:19.792217Z","iopub.execute_input":"2024-12-21T07:12:19.792490Z","iopub.status.idle":"2024-12-21T07:12:23.986830Z","shell.execute_reply.started":"2024-12-21T07:12:19.792470Z","shell.execute_reply":"2024-12-21T07:12:23.985956Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/adv-efficientnet-b4-44fb3a87.pth\" to /root/.cache/torch/hub/checkpoints/adv-efficientnet-b4-44fb3a87.pth\n100%|██████████| 74.4M/74.4M [00:01<00:00, 51.8MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Loaded pretrained weights for efficientnet-b4\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n         ZeroPad2d-1          [12, 3, 257, 257]               0\nConv2dStaticSamePadding-2         [12, 48, 128, 128]           1,296\n       BatchNorm2d-3         [12, 48, 128, 128]              96\nMemoryEfficientSwish-4         [12, 48, 128, 128]               0\n         ZeroPad2d-5         [12, 48, 130, 130]               0\nConv2dStaticSamePadding-6         [12, 48, 128, 128]             432\n       BatchNorm2d-7         [12, 48, 128, 128]              96\nMemoryEfficientSwish-8         [12, 48, 128, 128]               0\n          Identity-9             [12, 48, 1, 1]               0\nConv2dStaticSamePadding-10             [12, 12, 1, 1]             588\nMemoryEfficientSwish-11             [12, 12, 1, 1]               0\n         Identity-12             [12, 12, 1, 1]               0\nConv2dStaticSamePadding-13             [12, 48, 1, 1]             624\n         Identity-14         [12, 48, 128, 128]               0\nConv2dStaticSamePadding-15         [12, 24, 128, 128]           1,152\n      BatchNorm2d-16         [12, 24, 128, 128]              48\n      MBConvBlock-17         [12, 24, 128, 128]               0\n        ZeroPad2d-18         [12, 24, 130, 130]               0\nConv2dStaticSamePadding-19         [12, 24, 128, 128]             216\n      BatchNorm2d-20         [12, 24, 128, 128]              48\nMemoryEfficientSwish-21         [12, 24, 128, 128]               0\n         Identity-22             [12, 24, 1, 1]               0\nConv2dStaticSamePadding-23              [12, 6, 1, 1]             150\nMemoryEfficientSwish-24              [12, 6, 1, 1]               0\n         Identity-25              [12, 6, 1, 1]               0\nConv2dStaticSamePadding-26             [12, 24, 1, 1]             168\n         Identity-27         [12, 24, 128, 128]               0\nConv2dStaticSamePadding-28         [12, 24, 128, 128]             576\n      BatchNorm2d-29         [12, 24, 128, 128]              48\n      MBConvBlock-30         [12, 24, 128, 128]               0\n         Identity-31         [12, 24, 128, 128]               0\nConv2dStaticSamePadding-32        [12, 144, 128, 128]           3,456\n      BatchNorm2d-33        [12, 144, 128, 128]             288\nMemoryEfficientSwish-34        [12, 144, 128, 128]               0\n        ZeroPad2d-35        [12, 144, 129, 129]               0\nConv2dStaticSamePadding-36          [12, 144, 64, 64]           1,296\n      BatchNorm2d-37          [12, 144, 64, 64]             288\nMemoryEfficientSwish-38          [12, 144, 64, 64]               0\n         Identity-39            [12, 144, 1, 1]               0\nConv2dStaticSamePadding-40              [12, 6, 1, 1]             870\nMemoryEfficientSwish-41              [12, 6, 1, 1]               0\n         Identity-42              [12, 6, 1, 1]               0\nConv2dStaticSamePadding-43            [12, 144, 1, 1]           1,008\n         Identity-44          [12, 144, 64, 64]               0\nConv2dStaticSamePadding-45           [12, 32, 64, 64]           4,608\n      BatchNorm2d-46           [12, 32, 64, 64]              64\n      MBConvBlock-47           [12, 32, 64, 64]               0\n         Identity-48           [12, 32, 64, 64]               0\nConv2dStaticSamePadding-49          [12, 192, 64, 64]           6,144\n      BatchNorm2d-50          [12, 192, 64, 64]             384\nMemoryEfficientSwish-51          [12, 192, 64, 64]               0\n        ZeroPad2d-52          [12, 192, 66, 66]               0\nConv2dStaticSamePadding-53          [12, 192, 64, 64]           1,728\n      BatchNorm2d-54          [12, 192, 64, 64]             384\nMemoryEfficientSwish-55          [12, 192, 64, 64]               0\n         Identity-56            [12, 192, 1, 1]               0\nConv2dStaticSamePadding-57              [12, 8, 1, 1]           1,544\nMemoryEfficientSwish-58              [12, 8, 1, 1]               0\n         Identity-59              [12, 8, 1, 1]               0\nConv2dStaticSamePadding-60            [12, 192, 1, 1]           1,728\n         Identity-61          [12, 192, 64, 64]               0\nConv2dStaticSamePadding-62           [12, 32, 64, 64]           6,144\n      BatchNorm2d-63           [12, 32, 64, 64]              64\n      MBConvBlock-64           [12, 32, 64, 64]               0\n         Identity-65           [12, 32, 64, 64]               0\nConv2dStaticSamePadding-66          [12, 192, 64, 64]           6,144\n      BatchNorm2d-67          [12, 192, 64, 64]             384\nMemoryEfficientSwish-68          [12, 192, 64, 64]               0\n        ZeroPad2d-69          [12, 192, 66, 66]               0\nConv2dStaticSamePadding-70          [12, 192, 64, 64]           1,728\n      BatchNorm2d-71          [12, 192, 64, 64]             384\nMemoryEfficientSwish-72          [12, 192, 64, 64]               0\n         Identity-73            [12, 192, 1, 1]               0\nConv2dStaticSamePadding-74              [12, 8, 1, 1]           1,544\nMemoryEfficientSwish-75              [12, 8, 1, 1]               0\n         Identity-76              [12, 8, 1, 1]               0\nConv2dStaticSamePadding-77            [12, 192, 1, 1]           1,728\n         Identity-78          [12, 192, 64, 64]               0\nConv2dStaticSamePadding-79           [12, 32, 64, 64]           6,144\n      BatchNorm2d-80           [12, 32, 64, 64]              64\n      MBConvBlock-81           [12, 32, 64, 64]               0\n         Identity-82           [12, 32, 64, 64]               0\nConv2dStaticSamePadding-83          [12, 192, 64, 64]           6,144\n      BatchNorm2d-84          [12, 192, 64, 64]             384\nMemoryEfficientSwish-85          [12, 192, 64, 64]               0\n        ZeroPad2d-86          [12, 192, 66, 66]               0\nConv2dStaticSamePadding-87          [12, 192, 64, 64]           1,728\n      BatchNorm2d-88          [12, 192, 64, 64]             384\nMemoryEfficientSwish-89          [12, 192, 64, 64]               0\n         Identity-90            [12, 192, 1, 1]               0\nConv2dStaticSamePadding-91              [12, 8, 1, 1]           1,544\nMemoryEfficientSwish-92              [12, 8, 1, 1]               0\n         Identity-93              [12, 8, 1, 1]               0\nConv2dStaticSamePadding-94            [12, 192, 1, 1]           1,728\n         Identity-95          [12, 192, 64, 64]               0\nConv2dStaticSamePadding-96           [12, 32, 64, 64]           6,144\n      BatchNorm2d-97           [12, 32, 64, 64]              64\n      MBConvBlock-98           [12, 32, 64, 64]               0\n           Conv2d-99           [12, 32, 64, 64]           1,056\n          Conv2d-100           [12, 32, 64, 64]           1,056\n          Conv2d-101           [12, 32, 64, 64]           1,056\n          Conv2d-102           [12, 32, 64, 64]           9,248\n     BatchNorm2d-103           [12, 32, 64, 64]              64\n       LeakyReLU-104           [12, 32, 64, 64]               0\nMultiHeadedAttention-105           [12, 32, 64, 64]               0\n          Conv2d-106           [12, 32, 64, 64]           9,248\n     BatchNorm2d-107           [12, 32, 64, 64]              64\n       LeakyReLU-108           [12, 32, 64, 64]               0\n          Conv2d-109           [12, 32, 64, 64]           9,248\n     BatchNorm2d-110           [12, 32, 64, 64]              64\n       LeakyReLU-111           [12, 32, 64, 64]               0\n   FeedForward2D-112           [12, 32, 64, 64]               0\nTransformerBlock-113           [12, 32, 64, 64]               0\n      PatchTrans-114           [12, 32, 64, 64]               0\n    GlobalFilter-115           [12, 32, 64, 64]               0\n          Conv2d-116           [12, 32, 64, 64]           9,248\n     BatchNorm2d-117           [12, 32, 64, 64]              64\n       LeakyReLU-118           [12, 32, 64, 64]               0\n          Conv2d-119           [12, 32, 64, 64]           9,248\n     BatchNorm2d-120           [12, 32, 64, 64]              64\n       LeakyReLU-121           [12, 32, 64, 64]               0\n   FeedForward2D-122           [12, 32, 64, 64]               0\n       FreqBlock-123           [12, 32, 64, 64]               0\n          Conv2d-124           [12, 32, 64, 64]           1,056\n          Conv2d-125           [12, 32, 64, 64]           1,056\n          Conv2d-126           [12, 32, 64, 64]           1,056\n          Conv2d-127           [12, 32, 64, 64]           1,056\n     BatchNorm2d-128           [12, 32, 64, 64]              64\n       LeakyReLU-129           [12, 32, 64, 64]               0\n       CMA_Block-130           [12, 32, 64, 64]               0\n          Conv2d-131           [12, 32, 64, 64]           1,056\n          Conv2d-132           [12, 32, 64, 64]           1,056\n          Conv2d-133           [12, 32, 64, 64]           1,056\n          Conv2d-134           [12, 32, 64, 64]           9,248\n     BatchNorm2d-135           [12, 32, 64, 64]              64\n       LeakyReLU-136           [12, 32, 64, 64]               0\nMultiHeadedAttention-137           [12, 32, 64, 64]               0\n          Conv2d-138           [12, 32, 64, 64]           9,248\n     BatchNorm2d-139           [12, 32, 64, 64]              64\n       LeakyReLU-140           [12, 32, 64, 64]               0\n          Conv2d-141           [12, 32, 64, 64]           9,248\n     BatchNorm2d-142           [12, 32, 64, 64]              64\n       LeakyReLU-143           [12, 32, 64, 64]               0\n   FeedForward2D-144           [12, 32, 64, 64]               0\nTransformerBlock-145           [12, 32, 64, 64]               0\n      PatchTrans-146           [12, 32, 64, 64]               0\n    GlobalFilter-147           [12, 32, 64, 64]               0\n          Conv2d-148           [12, 32, 64, 64]           9,248\n     BatchNorm2d-149           [12, 32, 64, 64]              64\n       LeakyReLU-150           [12, 32, 64, 64]               0\n          Conv2d-151           [12, 32, 64, 64]           9,248\n     BatchNorm2d-152           [12, 32, 64, 64]              64\n       LeakyReLU-153           [12, 32, 64, 64]               0\n   FeedForward2D-154           [12, 32, 64, 64]               0\n       FreqBlock-155           [12, 32, 64, 64]               0\n          Conv2d-156           [12, 32, 64, 64]           1,056\n          Conv2d-157           [12, 32, 64, 64]           1,056\n          Conv2d-158           [12, 32, 64, 64]           1,056\n          Conv2d-159           [12, 32, 64, 64]           1,056\n     BatchNorm2d-160           [12, 32, 64, 64]              64\n       LeakyReLU-161           [12, 32, 64, 64]               0\n       CMA_Block-162           [12, 32, 64, 64]               0\n          Conv2d-163           [12, 32, 64, 64]           1,056\n          Conv2d-164           [12, 32, 64, 64]           1,056\n          Conv2d-165           [12, 32, 64, 64]           1,056\n          Conv2d-166           [12, 32, 64, 64]           9,248\n     BatchNorm2d-167           [12, 32, 64, 64]              64\n       LeakyReLU-168           [12, 32, 64, 64]               0\nMultiHeadedAttention-169           [12, 32, 64, 64]               0\n          Conv2d-170           [12, 32, 64, 64]           9,248\n     BatchNorm2d-171           [12, 32, 64, 64]              64\n       LeakyReLU-172           [12, 32, 64, 64]               0\n          Conv2d-173           [12, 32, 64, 64]           9,248\n     BatchNorm2d-174           [12, 32, 64, 64]              64\n       LeakyReLU-175           [12, 32, 64, 64]               0\n   FeedForward2D-176           [12, 32, 64, 64]               0\nTransformerBlock-177           [12, 32, 64, 64]               0\n      PatchTrans-178           [12, 32, 64, 64]               0\n    GlobalFilter-179           [12, 32, 64, 64]               0\n          Conv2d-180           [12, 32, 64, 64]           9,248\n     BatchNorm2d-181           [12, 32, 64, 64]              64\n       LeakyReLU-182           [12, 32, 64, 64]               0\n          Conv2d-183           [12, 32, 64, 64]           9,248\n     BatchNorm2d-184           [12, 32, 64, 64]              64\n       LeakyReLU-185           [12, 32, 64, 64]               0\n   FeedForward2D-186           [12, 32, 64, 64]               0\n       FreqBlock-187           [12, 32, 64, 64]               0\n          Conv2d-188           [12, 32, 64, 64]           1,056\n          Conv2d-189           [12, 32, 64, 64]           1,056\n          Conv2d-190           [12, 32, 64, 64]           1,056\n          Conv2d-191           [12, 32, 64, 64]           1,056\n     BatchNorm2d-192           [12, 32, 64, 64]              64\n       LeakyReLU-193           [12, 32, 64, 64]               0\n       CMA_Block-194           [12, 32, 64, 64]               0\n          Conv2d-195           [12, 32, 64, 64]           1,056\n          Conv2d-196           [12, 32, 64, 64]           1,056\n          Conv2d-197           [12, 32, 64, 64]           1,056\n          Conv2d-198           [12, 32, 64, 64]           9,248\n     BatchNorm2d-199           [12, 32, 64, 64]              64\n       LeakyReLU-200           [12, 32, 64, 64]               0\nMultiHeadedAttention-201           [12, 32, 64, 64]               0\n          Conv2d-202           [12, 32, 64, 64]           9,248\n     BatchNorm2d-203           [12, 32, 64, 64]              64\n       LeakyReLU-204           [12, 32, 64, 64]               0\n          Conv2d-205           [12, 32, 64, 64]           9,248\n     BatchNorm2d-206           [12, 32, 64, 64]              64\n       LeakyReLU-207           [12, 32, 64, 64]               0\n   FeedForward2D-208           [12, 32, 64, 64]               0\nTransformerBlock-209           [12, 32, 64, 64]               0\n      PatchTrans-210           [12, 32, 64, 64]               0\n    GlobalFilter-211           [12, 32, 64, 64]               0\n          Conv2d-212           [12, 32, 64, 64]           9,248\n     BatchNorm2d-213           [12, 32, 64, 64]              64\n       LeakyReLU-214           [12, 32, 64, 64]               0\n          Conv2d-215           [12, 32, 64, 64]           9,248\n     BatchNorm2d-216           [12, 32, 64, 64]              64\n       LeakyReLU-217           [12, 32, 64, 64]               0\n   FeedForward2D-218           [12, 32, 64, 64]               0\n       FreqBlock-219           [12, 32, 64, 64]               0\n          Conv2d-220           [12, 32, 64, 64]           1,056\n          Conv2d-221           [12, 32, 64, 64]           1,056\n          Conv2d-222           [12, 32, 64, 64]           1,056\n          Conv2d-223           [12, 32, 64, 64]           1,056\n     BatchNorm2d-224           [12, 32, 64, 64]              64\n       LeakyReLU-225           [12, 32, 64, 64]               0\n       CMA_Block-226           [12, 32, 64, 64]               0\n        Identity-227           [12, 32, 64, 64]               0\nConv2dStaticSamePadding-228          [12, 192, 64, 64]           6,144\n     BatchNorm2d-229          [12, 192, 64, 64]             384\nMemoryEfficientSwish-230          [12, 192, 64, 64]               0\n       ZeroPad2d-231          [12, 192, 67, 67]               0\nConv2dStaticSamePadding-232          [12, 192, 32, 32]           4,800\n     BatchNorm2d-233          [12, 192, 32, 32]             384\nMemoryEfficientSwish-234          [12, 192, 32, 32]               0\n        Identity-235            [12, 192, 1, 1]               0\nConv2dStaticSamePadding-236              [12, 8, 1, 1]           1,544\nMemoryEfficientSwish-237              [12, 8, 1, 1]               0\n        Identity-238              [12, 8, 1, 1]               0\nConv2dStaticSamePadding-239            [12, 192, 1, 1]           1,728\n        Identity-240          [12, 192, 32, 32]               0\nConv2dStaticSamePadding-241           [12, 56, 32, 32]          10,752\n     BatchNorm2d-242           [12, 56, 32, 32]             112\n     MBConvBlock-243           [12, 56, 32, 32]               0\n        Identity-244           [12, 56, 32, 32]               0\nConv2dStaticSamePadding-245          [12, 336, 32, 32]          18,816\n     BatchNorm2d-246          [12, 336, 32, 32]             672\nMemoryEfficientSwish-247          [12, 336, 32, 32]               0\n       ZeroPad2d-248          [12, 336, 36, 36]               0\nConv2dStaticSamePadding-249          [12, 336, 32, 32]           8,400\n     BatchNorm2d-250          [12, 336, 32, 32]             672\nMemoryEfficientSwish-251          [12, 336, 32, 32]               0\n        Identity-252            [12, 336, 1, 1]               0\nConv2dStaticSamePadding-253             [12, 14, 1, 1]           4,718\nMemoryEfficientSwish-254             [12, 14, 1, 1]               0\n        Identity-255             [12, 14, 1, 1]               0\nConv2dStaticSamePadding-256            [12, 336, 1, 1]           5,040\n        Identity-257          [12, 336, 32, 32]               0\nConv2dStaticSamePadding-258           [12, 56, 32, 32]          18,816\n     BatchNorm2d-259           [12, 56, 32, 32]             112\n     MBConvBlock-260           [12, 56, 32, 32]               0\n        Identity-261           [12, 56, 32, 32]               0\nConv2dStaticSamePadding-262          [12, 336, 32, 32]          18,816\n     BatchNorm2d-263          [12, 336, 32, 32]             672\nMemoryEfficientSwish-264          [12, 336, 32, 32]               0\n       ZeroPad2d-265          [12, 336, 36, 36]               0\nConv2dStaticSamePadding-266          [12, 336, 32, 32]           8,400\n     BatchNorm2d-267          [12, 336, 32, 32]             672\nMemoryEfficientSwish-268          [12, 336, 32, 32]               0\n        Identity-269            [12, 336, 1, 1]               0\nConv2dStaticSamePadding-270             [12, 14, 1, 1]           4,718\nMemoryEfficientSwish-271             [12, 14, 1, 1]               0\n        Identity-272             [12, 14, 1, 1]               0\nConv2dStaticSamePadding-273            [12, 336, 1, 1]           5,040\n        Identity-274          [12, 336, 32, 32]               0\nConv2dStaticSamePadding-275           [12, 56, 32, 32]          18,816\n     BatchNorm2d-276           [12, 56, 32, 32]             112\n     MBConvBlock-277           [12, 56, 32, 32]               0\n        Identity-278           [12, 56, 32, 32]               0\nConv2dStaticSamePadding-279          [12, 336, 32, 32]          18,816\n     BatchNorm2d-280          [12, 336, 32, 32]             672\nMemoryEfficientSwish-281          [12, 336, 32, 32]               0\n       ZeroPad2d-282          [12, 336, 36, 36]               0\nConv2dStaticSamePadding-283          [12, 336, 32, 32]           8,400\n     BatchNorm2d-284          [12, 336, 32, 32]             672\nMemoryEfficientSwish-285          [12, 336, 32, 32]               0\n        Identity-286            [12, 336, 1, 1]               0\nConv2dStaticSamePadding-287             [12, 14, 1, 1]           4,718\nMemoryEfficientSwish-288             [12, 14, 1, 1]               0\n        Identity-289             [12, 14, 1, 1]               0\nConv2dStaticSamePadding-290            [12, 336, 1, 1]           5,040\n        Identity-291          [12, 336, 32, 32]               0\nConv2dStaticSamePadding-292           [12, 56, 32, 32]          18,816\n     BatchNorm2d-293           [12, 56, 32, 32]             112\n     MBConvBlock-294           [12, 56, 32, 32]               0\n        Identity-295           [12, 56, 32, 32]               0\nConv2dStaticSamePadding-296          [12, 336, 32, 32]          18,816\n     BatchNorm2d-297          [12, 336, 32, 32]             672\nMemoryEfficientSwish-298          [12, 336, 32, 32]               0\n       ZeroPad2d-299          [12, 336, 33, 33]               0\nConv2dStaticSamePadding-300          [12, 336, 16, 16]           3,024\n     BatchNorm2d-301          [12, 336, 16, 16]             672\nMemoryEfficientSwish-302          [12, 336, 16, 16]               0\n        Identity-303            [12, 336, 1, 1]               0\nConv2dStaticSamePadding-304             [12, 14, 1, 1]           4,718\nMemoryEfficientSwish-305             [12, 14, 1, 1]               0\n        Identity-306             [12, 14, 1, 1]               0\nConv2dStaticSamePadding-307            [12, 336, 1, 1]           5,040\n        Identity-308          [12, 336, 16, 16]               0\nConv2dStaticSamePadding-309          [12, 112, 16, 16]          37,632\n     BatchNorm2d-310          [12, 112, 16, 16]             224\n     MBConvBlock-311          [12, 112, 16, 16]               0\n        Identity-312          [12, 112, 16, 16]               0\nConv2dStaticSamePadding-313          [12, 672, 16, 16]          75,264\n     BatchNorm2d-314          [12, 672, 16, 16]           1,344\nMemoryEfficientSwish-315          [12, 672, 16, 16]               0\n       ZeroPad2d-316          [12, 672, 18, 18]               0\nConv2dStaticSamePadding-317          [12, 672, 16, 16]           6,048\n     BatchNorm2d-318          [12, 672, 16, 16]           1,344\nMemoryEfficientSwish-319          [12, 672, 16, 16]               0\n        Identity-320            [12, 672, 1, 1]               0\nConv2dStaticSamePadding-321             [12, 28, 1, 1]          18,844\nMemoryEfficientSwish-322             [12, 28, 1, 1]               0\n        Identity-323             [12, 28, 1, 1]               0\nConv2dStaticSamePadding-324            [12, 672, 1, 1]          19,488\n        Identity-325          [12, 672, 16, 16]               0\nConv2dStaticSamePadding-326          [12, 112, 16, 16]          75,264\n     BatchNorm2d-327          [12, 112, 16, 16]             224\n     MBConvBlock-328          [12, 112, 16, 16]               0\n        Identity-329          [12, 112, 16, 16]               0\nConv2dStaticSamePadding-330          [12, 672, 16, 16]          75,264\n     BatchNorm2d-331          [12, 672, 16, 16]           1,344\nMemoryEfficientSwish-332          [12, 672, 16, 16]               0\n       ZeroPad2d-333          [12, 672, 18, 18]               0\nConv2dStaticSamePadding-334          [12, 672, 16, 16]           6,048\n     BatchNorm2d-335          [12, 672, 16, 16]           1,344\nMemoryEfficientSwish-336          [12, 672, 16, 16]               0\n        Identity-337            [12, 672, 1, 1]               0\nConv2dStaticSamePadding-338             [12, 28, 1, 1]          18,844\nMemoryEfficientSwish-339             [12, 28, 1, 1]               0\n        Identity-340             [12, 28, 1, 1]               0\nConv2dStaticSamePadding-341            [12, 672, 1, 1]          19,488\n        Identity-342          [12, 672, 16, 16]               0\nConv2dStaticSamePadding-343          [12, 112, 16, 16]          75,264\n     BatchNorm2d-344          [12, 112, 16, 16]             224\n     MBConvBlock-345          [12, 112, 16, 16]               0\n        Identity-346          [12, 112, 16, 16]               0\nConv2dStaticSamePadding-347          [12, 672, 16, 16]          75,264\n     BatchNorm2d-348          [12, 672, 16, 16]           1,344\nMemoryEfficientSwish-349          [12, 672, 16, 16]               0\n       ZeroPad2d-350          [12, 672, 18, 18]               0\nConv2dStaticSamePadding-351          [12, 672, 16, 16]           6,048\n     BatchNorm2d-352          [12, 672, 16, 16]           1,344\nMemoryEfficientSwish-353          [12, 672, 16, 16]               0\n        Identity-354            [12, 672, 1, 1]               0\nConv2dStaticSamePadding-355             [12, 28, 1, 1]          18,844\nMemoryEfficientSwish-356             [12, 28, 1, 1]               0\n        Identity-357             [12, 28, 1, 1]               0\nConv2dStaticSamePadding-358            [12, 672, 1, 1]          19,488\n        Identity-359          [12, 672, 16, 16]               0\nConv2dStaticSamePadding-360          [12, 112, 16, 16]          75,264\n     BatchNorm2d-361          [12, 112, 16, 16]             224\n     MBConvBlock-362          [12, 112, 16, 16]               0\n        Identity-363          [12, 112, 16, 16]               0\nConv2dStaticSamePadding-364          [12, 672, 16, 16]          75,264\n     BatchNorm2d-365          [12, 672, 16, 16]           1,344\nMemoryEfficientSwish-366          [12, 672, 16, 16]               0\n       ZeroPad2d-367          [12, 672, 18, 18]               0\nConv2dStaticSamePadding-368          [12, 672, 16, 16]           6,048\n     BatchNorm2d-369          [12, 672, 16, 16]           1,344\nMemoryEfficientSwish-370          [12, 672, 16, 16]               0\n        Identity-371            [12, 672, 1, 1]               0\nConv2dStaticSamePadding-372             [12, 28, 1, 1]          18,844\nMemoryEfficientSwish-373             [12, 28, 1, 1]               0\n        Identity-374             [12, 28, 1, 1]               0\nConv2dStaticSamePadding-375            [12, 672, 1, 1]          19,488\n        Identity-376          [12, 672, 16, 16]               0\nConv2dStaticSamePadding-377          [12, 112, 16, 16]          75,264\n     BatchNorm2d-378          [12, 112, 16, 16]             224\n     MBConvBlock-379          [12, 112, 16, 16]               0\n        Identity-380          [12, 112, 16, 16]               0\nConv2dStaticSamePadding-381          [12, 672, 16, 16]          75,264\n     BatchNorm2d-382          [12, 672, 16, 16]           1,344\nMemoryEfficientSwish-383          [12, 672, 16, 16]               0\n       ZeroPad2d-384          [12, 672, 18, 18]               0\nConv2dStaticSamePadding-385          [12, 672, 16, 16]           6,048\n     BatchNorm2d-386          [12, 672, 16, 16]           1,344\nMemoryEfficientSwish-387          [12, 672, 16, 16]               0\n        Identity-388            [12, 672, 1, 1]               0\nConv2dStaticSamePadding-389             [12, 28, 1, 1]          18,844\nMemoryEfficientSwish-390             [12, 28, 1, 1]               0\n        Identity-391             [12, 28, 1, 1]               0\nConv2dStaticSamePadding-392            [12, 672, 1, 1]          19,488\n        Identity-393          [12, 672, 16, 16]               0\nConv2dStaticSamePadding-394          [12, 112, 16, 16]          75,264\n     BatchNorm2d-395          [12, 112, 16, 16]             224\n     MBConvBlock-396          [12, 112, 16, 16]               0\n        Identity-397          [12, 112, 16, 16]               0\nConv2dStaticSamePadding-398          [12, 672, 16, 16]          75,264\n     BatchNorm2d-399          [12, 672, 16, 16]           1,344\nMemoryEfficientSwish-400          [12, 672, 16, 16]               0\n       ZeroPad2d-401          [12, 672, 20, 20]               0\nConv2dStaticSamePadding-402          [12, 672, 16, 16]          16,800\n     BatchNorm2d-403          [12, 672, 16, 16]           1,344\nMemoryEfficientSwish-404          [12, 672, 16, 16]               0\n        Identity-405            [12, 672, 1, 1]               0\nConv2dStaticSamePadding-406             [12, 28, 1, 1]          18,844\nMemoryEfficientSwish-407             [12, 28, 1, 1]               0\n        Identity-408             [12, 28, 1, 1]               0\nConv2dStaticSamePadding-409            [12, 672, 1, 1]          19,488\n        Identity-410          [12, 672, 16, 16]               0\nConv2dStaticSamePadding-411          [12, 160, 16, 16]         107,520\n     BatchNorm2d-412          [12, 160, 16, 16]             320\n     MBConvBlock-413          [12, 160, 16, 16]               0\n        Identity-414          [12, 160, 16, 16]               0\nConv2dStaticSamePadding-415          [12, 960, 16, 16]         153,600\n     BatchNorm2d-416          [12, 960, 16, 16]           1,920\nMemoryEfficientSwish-417          [12, 960, 16, 16]               0\n       ZeroPad2d-418          [12, 960, 20, 20]               0\nConv2dStaticSamePadding-419          [12, 960, 16, 16]          24,000\n     BatchNorm2d-420          [12, 960, 16, 16]           1,920\nMemoryEfficientSwish-421          [12, 960, 16, 16]               0\n        Identity-422            [12, 960, 1, 1]               0\nConv2dStaticSamePadding-423             [12, 40, 1, 1]          38,440\nMemoryEfficientSwish-424             [12, 40, 1, 1]               0\n        Identity-425             [12, 40, 1, 1]               0\nConv2dStaticSamePadding-426            [12, 960, 1, 1]          39,360\n        Identity-427          [12, 960, 16, 16]               0\nConv2dStaticSamePadding-428          [12, 160, 16, 16]         153,600\n     BatchNorm2d-429          [12, 160, 16, 16]             320\n     MBConvBlock-430          [12, 160, 16, 16]               0\n        Identity-431          [12, 160, 16, 16]               0\nConv2dStaticSamePadding-432          [12, 960, 16, 16]         153,600\n     BatchNorm2d-433          [12, 960, 16, 16]           1,920\nMemoryEfficientSwish-434          [12, 960, 16, 16]               0\n       ZeroPad2d-435          [12, 960, 20, 20]               0\nConv2dStaticSamePadding-436          [12, 960, 16, 16]          24,000\n     BatchNorm2d-437          [12, 960, 16, 16]           1,920\nMemoryEfficientSwish-438          [12, 960, 16, 16]               0\n        Identity-439            [12, 960, 1, 1]               0\nConv2dStaticSamePadding-440             [12, 40, 1, 1]          38,440\nMemoryEfficientSwish-441             [12, 40, 1, 1]               0\n        Identity-442             [12, 40, 1, 1]               0\nConv2dStaticSamePadding-443            [12, 960, 1, 1]          39,360\n        Identity-444          [12, 960, 16, 16]               0\nConv2dStaticSamePadding-445          [12, 160, 16, 16]         153,600\n     BatchNorm2d-446          [12, 160, 16, 16]             320\n     MBConvBlock-447          [12, 160, 16, 16]               0\n        Identity-448          [12, 160, 16, 16]               0\nConv2dStaticSamePadding-449          [12, 960, 16, 16]         153,600\n     BatchNorm2d-450          [12, 960, 16, 16]           1,920\nMemoryEfficientSwish-451          [12, 960, 16, 16]               0\n       ZeroPad2d-452          [12, 960, 20, 20]               0\nConv2dStaticSamePadding-453          [12, 960, 16, 16]          24,000\n     BatchNorm2d-454          [12, 960, 16, 16]           1,920\nMemoryEfficientSwish-455          [12, 960, 16, 16]               0\n        Identity-456            [12, 960, 1, 1]               0\nConv2dStaticSamePadding-457             [12, 40, 1, 1]          38,440\nMemoryEfficientSwish-458             [12, 40, 1, 1]               0\n        Identity-459             [12, 40, 1, 1]               0\nConv2dStaticSamePadding-460            [12, 960, 1, 1]          39,360\n        Identity-461          [12, 960, 16, 16]               0\nConv2dStaticSamePadding-462          [12, 160, 16, 16]         153,600\n     BatchNorm2d-463          [12, 160, 16, 16]             320\n     MBConvBlock-464          [12, 160, 16, 16]               0\n        Identity-465          [12, 160, 16, 16]               0\nConv2dStaticSamePadding-466          [12, 960, 16, 16]         153,600\n     BatchNorm2d-467          [12, 960, 16, 16]           1,920\nMemoryEfficientSwish-468          [12, 960, 16, 16]               0\n       ZeroPad2d-469          [12, 960, 20, 20]               0\nConv2dStaticSamePadding-470          [12, 960, 16, 16]          24,000\n     BatchNorm2d-471          [12, 960, 16, 16]           1,920\nMemoryEfficientSwish-472          [12, 960, 16, 16]               0\n        Identity-473            [12, 960, 1, 1]               0\nConv2dStaticSamePadding-474             [12, 40, 1, 1]          38,440\nMemoryEfficientSwish-475             [12, 40, 1, 1]               0\n        Identity-476             [12, 40, 1, 1]               0\nConv2dStaticSamePadding-477            [12, 960, 1, 1]          39,360\n        Identity-478          [12, 960, 16, 16]               0\nConv2dStaticSamePadding-479          [12, 160, 16, 16]         153,600\n     BatchNorm2d-480          [12, 160, 16, 16]             320\n     MBConvBlock-481          [12, 160, 16, 16]               0\n        Identity-482          [12, 160, 16, 16]               0\nConv2dStaticSamePadding-483          [12, 960, 16, 16]         153,600\n     BatchNorm2d-484          [12, 960, 16, 16]           1,920\nMemoryEfficientSwish-485          [12, 960, 16, 16]               0\n       ZeroPad2d-486          [12, 960, 20, 20]               0\nConv2dStaticSamePadding-487          [12, 960, 16, 16]          24,000\n     BatchNorm2d-488          [12, 960, 16, 16]           1,920\nMemoryEfficientSwish-489          [12, 960, 16, 16]               0\n        Identity-490            [12, 960, 1, 1]               0\nConv2dStaticSamePadding-491             [12, 40, 1, 1]          38,440\nMemoryEfficientSwish-492             [12, 40, 1, 1]               0\n        Identity-493             [12, 40, 1, 1]               0\nConv2dStaticSamePadding-494            [12, 960, 1, 1]          39,360\n        Identity-495          [12, 960, 16, 16]               0\nConv2dStaticSamePadding-496          [12, 160, 16, 16]         153,600\n     BatchNorm2d-497          [12, 160, 16, 16]             320\n     MBConvBlock-498          [12, 160, 16, 16]               0\n        Identity-499          [12, 160, 16, 16]               0\nConv2dStaticSamePadding-500          [12, 960, 16, 16]         153,600\n     BatchNorm2d-501          [12, 960, 16, 16]           1,920\nMemoryEfficientSwish-502          [12, 960, 16, 16]               0\n       ZeroPad2d-503          [12, 960, 19, 19]               0\nConv2dStaticSamePadding-504            [12, 960, 8, 8]          24,000\n     BatchNorm2d-505            [12, 960, 8, 8]           1,920\nMemoryEfficientSwish-506            [12, 960, 8, 8]               0\n        Identity-507            [12, 960, 1, 1]               0\nConv2dStaticSamePadding-508             [12, 40, 1, 1]          38,440\nMemoryEfficientSwish-509             [12, 40, 1, 1]               0\n        Identity-510             [12, 40, 1, 1]               0\nConv2dStaticSamePadding-511            [12, 960, 1, 1]          39,360\n        Identity-512            [12, 960, 8, 8]               0\nConv2dStaticSamePadding-513            [12, 272, 8, 8]         261,120\n     BatchNorm2d-514            [12, 272, 8, 8]             544\n     MBConvBlock-515            [12, 272, 8, 8]               0\n        Identity-516            [12, 272, 8, 8]               0\nConv2dStaticSamePadding-517           [12, 1632, 8, 8]         443,904\n     BatchNorm2d-518           [12, 1632, 8, 8]           3,264\nMemoryEfficientSwish-519           [12, 1632, 8, 8]               0\n       ZeroPad2d-520         [12, 1632, 12, 12]               0\nConv2dStaticSamePadding-521           [12, 1632, 8, 8]          40,800\n     BatchNorm2d-522           [12, 1632, 8, 8]           3,264\nMemoryEfficientSwish-523           [12, 1632, 8, 8]               0\n        Identity-524           [12, 1632, 1, 1]               0\nConv2dStaticSamePadding-525             [12, 68, 1, 1]         111,044\nMemoryEfficientSwish-526             [12, 68, 1, 1]               0\n        Identity-527             [12, 68, 1, 1]               0\nConv2dStaticSamePadding-528           [12, 1632, 1, 1]         112,608\n        Identity-529           [12, 1632, 8, 8]               0\nConv2dStaticSamePadding-530            [12, 272, 8, 8]         443,904\n     BatchNorm2d-531            [12, 272, 8, 8]             544\n     MBConvBlock-532            [12, 272, 8, 8]               0\n        Identity-533            [12, 272, 8, 8]               0\nConv2dStaticSamePadding-534           [12, 1632, 8, 8]         443,904\n     BatchNorm2d-535           [12, 1632, 8, 8]           3,264\nMemoryEfficientSwish-536           [12, 1632, 8, 8]               0\n       ZeroPad2d-537         [12, 1632, 12, 12]               0\nConv2dStaticSamePadding-538           [12, 1632, 8, 8]          40,800\n     BatchNorm2d-539           [12, 1632, 8, 8]           3,264\nMemoryEfficientSwish-540           [12, 1632, 8, 8]               0\n        Identity-541           [12, 1632, 1, 1]               0\nConv2dStaticSamePadding-542             [12, 68, 1, 1]         111,044\nMemoryEfficientSwish-543             [12, 68, 1, 1]               0\n        Identity-544             [12, 68, 1, 1]               0\nConv2dStaticSamePadding-545           [12, 1632, 1, 1]         112,608\n        Identity-546           [12, 1632, 8, 8]               0\nConv2dStaticSamePadding-547            [12, 272, 8, 8]         443,904\n     BatchNorm2d-548            [12, 272, 8, 8]             544\n     MBConvBlock-549            [12, 272, 8, 8]               0\n        Identity-550            [12, 272, 8, 8]               0\nConv2dStaticSamePadding-551           [12, 1632, 8, 8]         443,904\n     BatchNorm2d-552           [12, 1632, 8, 8]           3,264\nMemoryEfficientSwish-553           [12, 1632, 8, 8]               0\n       ZeroPad2d-554         [12, 1632, 12, 12]               0\nConv2dStaticSamePadding-555           [12, 1632, 8, 8]          40,800\n     BatchNorm2d-556           [12, 1632, 8, 8]           3,264\nMemoryEfficientSwish-557           [12, 1632, 8, 8]               0\n        Identity-558           [12, 1632, 1, 1]               0\nConv2dStaticSamePadding-559             [12, 68, 1, 1]         111,044\nMemoryEfficientSwish-560             [12, 68, 1, 1]               0\n        Identity-561             [12, 68, 1, 1]               0\nConv2dStaticSamePadding-562           [12, 1632, 1, 1]         112,608\n        Identity-563           [12, 1632, 8, 8]               0\nConv2dStaticSamePadding-564            [12, 272, 8, 8]         443,904\n     BatchNorm2d-565            [12, 272, 8, 8]             544\n     MBConvBlock-566            [12, 272, 8, 8]               0\n        Identity-567            [12, 272, 8, 8]               0\nConv2dStaticSamePadding-568           [12, 1632, 8, 8]         443,904\n     BatchNorm2d-569           [12, 1632, 8, 8]           3,264\nMemoryEfficientSwish-570           [12, 1632, 8, 8]               0\n       ZeroPad2d-571         [12, 1632, 12, 12]               0\nConv2dStaticSamePadding-572           [12, 1632, 8, 8]          40,800\n     BatchNorm2d-573           [12, 1632, 8, 8]           3,264\nMemoryEfficientSwish-574           [12, 1632, 8, 8]               0\n        Identity-575           [12, 1632, 1, 1]               0\nConv2dStaticSamePadding-576             [12, 68, 1, 1]         111,044\nMemoryEfficientSwish-577             [12, 68, 1, 1]               0\n        Identity-578             [12, 68, 1, 1]               0\nConv2dStaticSamePadding-579           [12, 1632, 1, 1]         112,608\n        Identity-580           [12, 1632, 8, 8]               0\nConv2dStaticSamePadding-581            [12, 272, 8, 8]         443,904\n     BatchNorm2d-582            [12, 272, 8, 8]             544\n     MBConvBlock-583            [12, 272, 8, 8]               0\n        Identity-584            [12, 272, 8, 8]               0\nConv2dStaticSamePadding-585           [12, 1632, 8, 8]         443,904\n     BatchNorm2d-586           [12, 1632, 8, 8]           3,264\nMemoryEfficientSwish-587           [12, 1632, 8, 8]               0\n       ZeroPad2d-588         [12, 1632, 12, 12]               0\nConv2dStaticSamePadding-589           [12, 1632, 8, 8]          40,800\n     BatchNorm2d-590           [12, 1632, 8, 8]           3,264\nMemoryEfficientSwish-591           [12, 1632, 8, 8]               0\n        Identity-592           [12, 1632, 1, 1]               0\nConv2dStaticSamePadding-593             [12, 68, 1, 1]         111,044\nMemoryEfficientSwish-594             [12, 68, 1, 1]               0\n        Identity-595             [12, 68, 1, 1]               0\nConv2dStaticSamePadding-596           [12, 1632, 1, 1]         112,608\n        Identity-597           [12, 1632, 8, 8]               0\nConv2dStaticSamePadding-598            [12, 272, 8, 8]         443,904\n     BatchNorm2d-599            [12, 272, 8, 8]             544\n     MBConvBlock-600            [12, 272, 8, 8]               0\n        Identity-601            [12, 272, 8, 8]               0\nConv2dStaticSamePadding-602           [12, 1632, 8, 8]         443,904\n     BatchNorm2d-603           [12, 1632, 8, 8]           3,264\nMemoryEfficientSwish-604           [12, 1632, 8, 8]               0\n       ZeroPad2d-605         [12, 1632, 12, 12]               0\nConv2dStaticSamePadding-606           [12, 1632, 8, 8]          40,800\n     BatchNorm2d-607           [12, 1632, 8, 8]           3,264\nMemoryEfficientSwish-608           [12, 1632, 8, 8]               0\n        Identity-609           [12, 1632, 1, 1]               0\nConv2dStaticSamePadding-610             [12, 68, 1, 1]         111,044\nMemoryEfficientSwish-611             [12, 68, 1, 1]               0\n        Identity-612             [12, 68, 1, 1]               0\nConv2dStaticSamePadding-613           [12, 1632, 1, 1]         112,608\n        Identity-614           [12, 1632, 8, 8]               0\nConv2dStaticSamePadding-615            [12, 272, 8, 8]         443,904\n     BatchNorm2d-616            [12, 272, 8, 8]             544\n     MBConvBlock-617            [12, 272, 8, 8]               0\n        Identity-618            [12, 272, 8, 8]               0\nConv2dStaticSamePadding-619           [12, 1632, 8, 8]         443,904\n     BatchNorm2d-620           [12, 1632, 8, 8]           3,264\nMemoryEfficientSwish-621           [12, 1632, 8, 8]               0\n       ZeroPad2d-622         [12, 1632, 12, 12]               0\nConv2dStaticSamePadding-623           [12, 1632, 8, 8]          40,800\n     BatchNorm2d-624           [12, 1632, 8, 8]           3,264\nMemoryEfficientSwish-625           [12, 1632, 8, 8]               0\n        Identity-626           [12, 1632, 1, 1]               0\nConv2dStaticSamePadding-627             [12, 68, 1, 1]         111,044\nMemoryEfficientSwish-628             [12, 68, 1, 1]               0\n        Identity-629             [12, 68, 1, 1]               0\nConv2dStaticSamePadding-630           [12, 1632, 1, 1]         112,608\n        Identity-631           [12, 1632, 8, 8]               0\nConv2dStaticSamePadding-632            [12, 272, 8, 8]         443,904\n     BatchNorm2d-633            [12, 272, 8, 8]             544\n     MBConvBlock-634            [12, 272, 8, 8]               0\n        Identity-635            [12, 272, 8, 8]               0\nConv2dStaticSamePadding-636           [12, 1632, 8, 8]         443,904\n     BatchNorm2d-637           [12, 1632, 8, 8]           3,264\nMemoryEfficientSwish-638           [12, 1632, 8, 8]               0\n       ZeroPad2d-639         [12, 1632, 10, 10]               0\nConv2dStaticSamePadding-640           [12, 1632, 8, 8]          14,688\n     BatchNorm2d-641           [12, 1632, 8, 8]           3,264\nMemoryEfficientSwish-642           [12, 1632, 8, 8]               0\n        Identity-643           [12, 1632, 1, 1]               0\nConv2dStaticSamePadding-644             [12, 68, 1, 1]         111,044\nMemoryEfficientSwish-645             [12, 68, 1, 1]               0\n        Identity-646             [12, 68, 1, 1]               0\nConv2dStaticSamePadding-647           [12, 1632, 1, 1]         112,608\n        Identity-648           [12, 1632, 8, 8]               0\nConv2dStaticSamePadding-649            [12, 448, 8, 8]         731,136\n     BatchNorm2d-650            [12, 448, 8, 8]             896\n     MBConvBlock-651            [12, 448, 8, 8]               0\n        Identity-652            [12, 448, 8, 8]               0\nConv2dStaticSamePadding-653           [12, 2688, 8, 8]       1,204,224\n     BatchNorm2d-654           [12, 2688, 8, 8]           5,376\nMemoryEfficientSwish-655           [12, 2688, 8, 8]               0\n       ZeroPad2d-656         [12, 2688, 10, 10]               0\nConv2dStaticSamePadding-657           [12, 2688, 8, 8]          24,192\n     BatchNorm2d-658           [12, 2688, 8, 8]           5,376\nMemoryEfficientSwish-659           [12, 2688, 8, 8]               0\n        Identity-660           [12, 2688, 1, 1]               0\nConv2dStaticSamePadding-661            [12, 112, 1, 1]         301,168\nMemoryEfficientSwish-662            [12, 112, 1, 1]               0\n        Identity-663            [12, 112, 1, 1]               0\nConv2dStaticSamePadding-664           [12, 2688, 1, 1]         303,744\n        Identity-665           [12, 2688, 8, 8]               0\nConv2dStaticSamePadding-666            [12, 448, 8, 8]       1,204,224\n     BatchNorm2d-667            [12, 448, 8, 8]             896\n     MBConvBlock-668            [12, 448, 8, 8]               0\n        Identity-669            [12, 448, 8, 8]               0\nConv2dStaticSamePadding-670           [12, 1792, 8, 8]         802,816\n     BatchNorm2d-671           [12, 1792, 8, 8]           3,584\nMemoryEfficientSwish-672           [12, 1792, 8, 8]               0\n         Dropout-673                 [12, 1792]               0\n          Linear-674                    [12, 2]           3,586\n    Classifier2D-675                    [12, 2]               0\n================================================================\nTotal params: 17,768,266\nTrainable params: 17,768,266\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 9.00\nForward/backward pass size (MB): 9942.94\nParams size (MB): 67.78\nEstimated Total Size (MB): 10019.72\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"def normalize(img, eps=1e-8):\n    min = np.min(img)\n    max = np.max(img)\n\n    norm_img = (img-min)/(max-min+eps)\n    \n    return norm_img\n\n\n\n\ndef read_data(path):\n    img_ids=[]\n    targets=[]\n    \n    with open (path, 'r') as file:\n        reader = csv.reader(file)\n        next(reader)\n        for row in reader:\n            if len(row)==2:\n                img_id, target = row\n                img_ids.append(img_id)\n                targets.append(target)\n                \n    return img_ids, targets\n\n\n\ndef onehot_encode(logits):\n    num_classes = logits.shape[1]\n    max_indices = torch.argmax(logits, dim=1)\n    \n    result = F.one_hot(max_indices, num_classes=num_classes)\n    return(result)\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T07:12:23.987984Z","iopub.execute_input":"2024-12-21T07:12:23.988289Z","iopub.status.idle":"2024-12-21T07:12:23.993741Z","shell.execute_reply.started":"2024-12-21T07:12:23.988256Z","shell.execute_reply":"2024-12-21T07:12:23.993002Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class CreateDataset(Dataset):\n    def __init__(self, dir_path, label_path, transform=None):\n        self.data_path = dir_path\n        self.label_path = label_path\n        self.transform = transform\n        \n        self.imgfiles, self.labels = read_data(label_path)\n        \n\n    def __len__(self):\n        return len(self.imgfiles)\n        \n    def __getitem__(self, index):\n        imgpath = os.path.join(self.data_path, self.imgfiles[index])\n        img = imageio.imread(imgpath)\n\n        img = normalize(img)\n        \n        if self.transform is not None:\n            img = self.transform(img)\n\n        label = int(self.labels[index])\n        label_arr = np.zeros(2)\n        label_arr[label] = 1\n        \n        return img, label_arr","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T07:12:23.994647Z","iopub.execute_input":"2024-12-21T07:12:23.994921Z","iopub.status.idle":"2024-12-21T07:12:24.017352Z","shell.execute_reply.started":"2024-12-21T07:12:23.994896Z","shell.execute_reply":"2024-12-21T07:12:24.016641Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"data_folder = '/kaggle/input/deepfake/phase1/trainset'\nlabel_path = '/kaggle/input/deepfake/phase1/trainset_label.txt'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T07:12:24.018146Z","iopub.execute_input":"2024-12-21T07:12:24.018519Z","iopub.status.idle":"2024-12-21T07:12:24.033180Z","shell.execute_reply.started":"2024-12-21T07:12:24.018489Z","shell.execute_reply":"2024-12-21T07:12:24.032499Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.CenterCrop(256),\n    transforms.ConvertImageDtype(torch.float32)\n])\n\ndataset=CreateDataset(data_folder, label_path, transform)\n\ntrain_size = int(0.9*len(dataset))\nval_size = len(dataset) - train_size\n\ntrain_dataset, val_dataset = random_split(dataset,[train_size, val_size])\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=100, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T07:12:24.033880Z","iopub.execute_input":"2024-12-21T07:12:24.034101Z","iopub.status.idle":"2024-12-21T07:12:24.569552Z","shell.execute_reply.started":"2024-12-21T07:12:24.034073Z","shell.execute_reply":"2024-12-21T07:12:24.568806Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nnum_epochs= 3\nlr = 0.0001\n\ntotal_loss = 0\ntrainloss_list = []\n\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.75, patience=15, min_lr=1e-5)\n\ncriterion = nn.CrossEntropyLoss()\n\nfor epoch in range (num_epochs):\n    model.train()\n    for (idx,(x_train, y_true)) in enumerate(train_dataloader):\n        \n        \n        x_train, y_true = x_train.to(device), y_true.to(device)\n    \n        optimizer.zero_grad()\n        \n        output = model(x_train)\n        y_pred = output['logits']\n\n        \n    \n        loss = criterion(y_pred, y_true)\n        loss.backward()\n    \n        optimizer.step()\n    \n        total_loss += loss\n\n        if idx%1000==0:\n            print(f'\\trunning epoch {epoch+1} ......')\n    \n    train_loss = total_loss/len(train_dataset)\n    trainloss_list.append(train_loss.item())\n    \n    \n    val_loss = 0\n    valloss_list = []\n\n    \n    model.eval()\n    with torch.no_grad():\n        for (x_val, y_true) in val_dataloader:\n            \n            x_val, y_true = x_val.to(device), y_true.to(device).reshape(-1,1)\n            \n            output = model(x_val)\n            y_pred = output['logits']\n    \n            val_loss += criterion(y_pred, y_true)\n    \n            scheduler.step(val_loss)\n            '''\n            class_pred = sigmoid_threshold(y_pred)\n            \n            tn, fp, fn, tp = confusion_matrix(y_true, class_pred).ravel()\n            TP.extend(tp)\n            FP.extend(fp)\n            TN.extend(tn)\n            FN.extend(fn)\n            '''\n        val_loss = val_loss/len(val_dataset)\n        valloss_list.append(val_loss.item())\n\n        \n    \n    current_lr = optimizer.param_groups[0]['lr']\n    \n    print(f'{epoch+1}|{num_epochs} train loss: {train_loss},  val loss: {val_loss},  lr: {current_lr:.6f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T07:34:39.358836Z","iopub.execute_input":"2024-12-21T07:34:39.359159Z","execution_failed":"2024-12-21T09:02:48.290Z"}},"outputs":[{"name":"stdout","text":"\trunning epoch 1 ......\n\trunning epoch 1 ......\n\trunning epoch 1 ......\n\trunning epoch 1 ......\n\trunning epoch 1 ......\n\trunning epoch 1 ......\n\trunning epoch 1 ......\n\trunning epoch 1 ......\n\trunning epoch 1 ......\n\trunning epoch 1 ......\n\trunning epoch 1 ......\n\trunning epoch 1 ......\n\trunning epoch 1 ......\n\trunning epoch 1 ......\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"output = {\"logits\": logits, \"mask\": mask, \"features:\": features}","metadata":{}},{"cell_type":"code","source":"path = '/kaggle/working/model_weights.pth'\ntorch.save(model.state_dict(), path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print(f'labels: {label}\\n')\n# print('predictions:', onehot_encode(output['logits']))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# softmax = nn.Softmax()\n# pred = torch.tensor([[-0.1362, -0.0531],\n#         [ 0.0268,  0.0570]])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# torch.argmax(pred, dim=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}